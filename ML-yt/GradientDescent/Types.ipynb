{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch GD + nd Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y = w0 + w1x1 + w2x2...\n",
    "wi = wi - lr*slope_wrt_wi\n",
    "\n",
    "w = n+1 dim vector\n",
    "\n",
    "dJ/dw_j = 1/n*sum[ (y_i - y_i_hat)*x_i_j ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10) (442,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np\n",
    "X,y = load_diabetes(return_X_y=True)\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -14.42294414, -212.22245179,  494.64228515,  394.2090426 ,\n",
       "       -461.75718406,  259.39729229, -111.2606147 ,   -6.12278411,\n",
       "        625.74161571,   55.64822356])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(xtrain,ytrain)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152.41099566843042"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MY_GD_Regressor:\n",
    "    def __init__(self,epochs = 100,lr = 0.01):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self,xtrain,ytrain):\n",
    "        w = np.ones(xtrain.shape[1])\n",
    "        b = 10\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            # vectorization\n",
    "            y_hat = np.dot(xtrain,w) + b\n",
    "            b = b - self.lr * np.mean(y_hat - ytrain)\n",
    "            w = w - (self.lr *np.dot((y_hat - ytrain),xtrain)/xtrain.shape[0])\n",
    "\n",
    "        self.coef_ = w\n",
    "        self.intercept_ = b\n",
    "\n",
    "    def predict(self,xtest):\n",
    "        return np.dot(xtest,self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "My_gd = MY_GD_Regressor(epochs=1000,lr=0.5)\n",
    "My_gd.fit(xtrain , ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.511105210740566"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = My_gd.predict(xtest)\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(ytest,ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic GD ==> Fast Convergence => Based on randomness \n",
    "### Mostly used in DL as fast and optimized for space\n",
    "\n",
    "1. Batch GD take too much operations/computation ==> Becomes slow on large dataset\n",
    "2. Batch GD has problem with hardware also ==> on LOW RAM problem occurs\n",
    "\n",
    "### ST GD\n",
    "##### See from animation ST doesn't always get better from last iter but eventually reaches the solution\n",
    "1. In batch GD we update after entire data analyzed but in ST-GD we update after each row analysation\n",
    "2. Less epochs required as we reach early\n",
    "3. We dont need to load entire data we need 1 row at a time hence RAM not a problem now\n",
    "4. y_hat will be a scaler\n",
    "\n",
    "#### For same number of epochs Batch Gd fast but overall ST fast as it need less epochs\n",
    "\n",
    "1. best for non convex function Batch GD donot give global min \n",
    "2. Non convex ==> more than 1 minimas in curve/surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MY_GD_Regressor_ST:\n",
    "    def __init__(self,epochs = 100,lr = 0.01):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self,xtrain,ytrain):\n",
    "        w = np.ones(xtrain.shape[1])\n",
    "        b = 10\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            for j in range(xtrain.shape[0]):\n",
    "                random_idx = np.random.randint(0,xtrain.shape[0])\n",
    "\n",
    "                y_hat = np.dot(xtrain[random_idx],w) + b\n",
    "                b = b - self.lr *(y_hat - ytrain[random_idx])\n",
    "                w = w - self.lr *np.dot((y_hat - ytrain[random_idx]),xtrain[random_idx])\n",
    "                \n",
    "        self.coef_ = w\n",
    "        self.intercept_ = b\n",
    "\n",
    "    def predict(self,xtest):\n",
    "        return np.dot(xtest,self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45559512753542264"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "My_gd1 = MY_GD_Regressor_ST(epochs=50,lr=0.1)\n",
    "My_gd1.fit(xtrain , ytrain)\n",
    "ypred = My_gd1.predict(xtest)\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(ytest,ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Batch GD\n",
    "1. We make group of rows called batch \n",
    "2. we make updates after analysing a batch\n",
    "3. N Batches = ST GD, 1 Batch = Batch GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class MY_GD_Regressor_MINI_BATCH:\n",
    "    def __init__(self,batch_size,epochs = 100,lr = 0.01):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def fit(self,xtrain,ytrain):\n",
    "        w = np.ones(xtrain.shape[1])\n",
    "        b = 0\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            for j in range(xtrain.shape[0]//self.batch_size):\n",
    "                random_batch = random.sample(range(xtrain.shape[0]),self.batch_size)\n",
    "\n",
    "                y_hat = np.dot(xtrain[random_batch],w) + b\n",
    "                b = b - self.lr * np.mean((y_hat - ytrain[random_batch]))\n",
    "                w = w - self.lr *np.dot((y_hat - ytrain[random_batch]),xtrain[random_batch])\n",
    "                \n",
    "        self.coef_ = w\n",
    "        self.intercept_ = b\n",
    "\n",
    "    def predict(self,xtest):\n",
    "        return np.dot(xtest,self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5256134094549896"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "My_gd = MY_GD_Regressor_MINI_BATCH(batch_size= xtrain.shape[0]//20,epochs=50,lr=0.1)\n",
    "My_gd.fit(xtrain , ytrain)\n",
    "ypred = My_gd.predict(xtest)\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(ytest,ypred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
