{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "from keras.layers import Dense,Dropout,LSTM\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All CSV Files in a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = ['003.csv', '064.csv', '070.csv', '088.csv', '135.csv', '143.csv', '168.csv', '169.csv', '213.csv', '226.csv', '228.csv', '230.csv', '234.csv', '274.csv', '319.csv', '355.csv', '367.csv', '374.csv', '376.csv', '387.csv', '390.csv', '405.csv', '416.csv', '433.csv', '436.csv', '445.csv', '473.csv', '484.csv', '495.csv', '528.csv', '542.csv', '546.csv', '552.csv', '558.csv', '559.csv', '577.csv', '592.csv', '614.csv', '640.csv', '645.csv', '653.csv', '662.csv', '665.csv', '702.csv', '791.csv', '804.csv', '859.csv', '875.csv', '914.csv','958.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def get_next_100_dates_excluding_weekends(start_date, exclude_weekends=True):\n",
    "\n",
    "  dates = []\n",
    "  current_date = start_date\n",
    "  while(len(dates)!=100):\n",
    "    current_date += datetime.timedelta(days=1)\n",
    "    if exclude_weekends and current_date.weekday() in [5, 6]:\n",
    "      continue\n",
    "    dates.append(current_date)\n",
    "  return dates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing Outliers in Given Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_outliers_iqr(dataframe):\n",
    "    for column in dataframe.drop(columns=['Date']).columns:\n",
    "        Q1 = dataframe[column].quantile(0.25)\n",
    "        Q3 = dataframe[column].quantile(0.75)\n",
    "        Q2 = dataframe[column].quantile(0.50)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_limit = Q1 - 1.5 * IQR\n",
    "        upper_limit = Q3 + 1.5 * IQR\n",
    "        dataframe[column] = dataframe[column].apply(lambda x: lower_limit if x < lower_limit else upper_limit if x > upper_limit else x)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Moving_Avg(df):\n",
    "    ma_100_days = df['Close'].rolling(100).mean()\n",
    "    plt.plot(df['Close'],c='r')\n",
    "    plt.plot(ma_100_days,c='b')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions Using Prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_prophet(path):\n",
    "  df = pd.read_csv(path)\n",
    "  df = fix_outliers_iqr(df)\n",
    "  df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "  df = df[['Date','Close']]\n",
    "  df.columns = ['ds','y']\n",
    "\n",
    "  model = Prophet()\n",
    "  model.fit(df)\n",
    "\n",
    "  # Predicting closing price for next 100 days\n",
    "  prediction_dates = model.make_future_dataframe(periods=100)\n",
    "  predictions = model.predict(prediction_dates) \n",
    "  model.plot(predictions).show()\n",
    "\n",
    "  pred_df = predictions[['ds','yhat']][-100:]\n",
    "  pred_df.columns = ['Date','Price']\n",
    "\n",
    "  ids=[]\n",
    "  for i in range(1,101):\n",
    "    ID = f\"{os.path.splitext(os.path.basename(path))[0]}_#{i}\"\n",
    "    ids.append(ID)\n",
    "\n",
    "  pred_df['ID'] = ids\n",
    "  print(pred_df)\n",
    "  return pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction using ARIMA\n",
    "1. ARIMA gave the best results for predicting stock prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the function made to get best values of P,Q,D \n",
    "1. Though It didn't help much in getting the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grid_search_arima(data, p_range, d_range, q_range):\n",
    "    stock_prices = data\n",
    "    time_series = pd.Series(stock_prices)\n",
    "    train_data = time_series[1:len(time_series)-200]\n",
    "    test_data = time_series[len(time_series)-200:]\n",
    "    \n",
    "    p_values = [0,1,2,3,5,7]\n",
    "    d_values = range(0, 3)\n",
    "    q_values = range(0, 3)\n",
    "    min_error = 1000000000\n",
    "    best = ()\n",
    "    \n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p,d,q)\n",
    "                warnings.filterwarnings(\"ignore\")\n",
    "                model = ARIMA(train_data, order=order).fit()\n",
    "                predictions = model.predict(start=len(train_data), end=len(train_data) + len(test_data)-1)\n",
    "                error = mean_squared_error(test_data, predictions)\n",
    "\n",
    "                if(error<min_error) :\n",
    "                    min_error = error\n",
    "                    best = order\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_arima(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    # df = fix_outliers_iqr(df)  // Best reslts were got when we didn't fix the outliers\n",
    "    boxcox = PowerTransformer(method=\"box-cox\")\n",
    "\n",
    "    xtrain = boxcox.fit_transform(np.array(df['Close']).reshape(-1,1))\n",
    "\n",
    "    model = ARIMA(xtrain,order=(7,1,1))\n",
    "\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    next_100 = model_fit.forecast(100)\n",
    "\n",
    "    ids=[]\n",
    "    for i in range(1,101):\n",
    "        ID = f\"{os.path.splitext(os.path.basename(path))[0]}_#{i}\"\n",
    "        ids.append(ID)\n",
    "\n",
    "    y_pred = list(boxcox.inverse_transform(np.array(next_100).reshape(-1,1)))\n",
    "    pred_df=pd.DataFrame({'ID':ids,'Price':[i[0] for i in y_pred]})\n",
    "\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Keras(x,y,x1,x_input,epochs):\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    "    start_from_epoch=0,\n",
    ")\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape= (x.shape[1], 1)))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss=\"mean_squared_error\")\n",
    "    model.fit(x,y,epochs=epochs,verbose=1,batch_size=5,callbacks=[callback])\n",
    "    \n",
    "    y_pred = model.predict(x1)\n",
    "    \n",
    "    for i in range(100):\n",
    "        pred = model.predict(x_input.T[-10:])\n",
    "        x_input=np.append(x_input,pred,axis=0)\n",
    "        y_pred=np.append(y_pred,pred,axis=0)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function To split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset.values)-time_step-1):\n",
    "\t\ta = dataset.values[i:(i+time_step), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset.values[i + time_step, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_LSTM(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    # df = fix_outliers_iqr(df)\n",
    "    mx = StandardScaler()\n",
    "    \n",
    "    Close = mx.fit_transform(np.array(df['Close']).reshape(-1,1))\n",
    "    split_ratio = 0.8 \n",
    "    split_index = int(split_ratio * len(Close))\n",
    "\n",
    "    xtrain = pd.DataFrame(Close[:split_index])\n",
    "    xtest = pd.DataFrame(Close[split_index:])\n",
    "\n",
    "    x,y = create_dataset(xtrain,50)\n",
    "    x1,y1= create_dataset(xtest,50)\n",
    "    x_input= xtest.values[-100:]\n",
    "\n",
    "    ypred = Keras(x,y,x1,x_input,epochs=5)\n",
    "    ypred = mx.inverse_transform(ypred)[-100:]\n",
    "    ypred = ypred.reshape((1,ypred.shape[0])).ravel()\n",
    "    \n",
    "    ids=[]\n",
    "    for i in range(1,101):\n",
    "        ID = f\"{os.path.splitext(os.path.basename(path))[0]}_#{i}\"\n",
    "        ids.append(ID)\n",
    "\n",
    "    pred_df=pd.DataFrame({'ID':ids,'Price':ypred})\n",
    "\n",
    "    return pred_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function To Write Into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(dfs):  \n",
    "    # write_to = pd.read_csv('submit.csv')\n",
    "    updated_df = pd.concat(dfs)\n",
    "    updated_df.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A CSV file was initiated beforehand with column names ID and Price\n",
    "1. File with name submit.csv was made already where we wrote our predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=[]\n",
    "for csv in csv_files:\n",
    "\n",
    "    pred = predictor_arima(f'./mine-the-model-2023/Upload-Dataset/TRAIN/{csv}')\n",
    "    # pred = predictor_prophet(f'./mine-the-model-2023/Upload-Dataset/TRAIN/{csv}')\n",
    "    # pred = predictor_LSTM(f'./mine-the-model-2023/Upload-Dataset/TRAIN/{csv}')\n",
    "    data = pd.DataFrame({'ID': pred['ID'], 'Price':[i for i in pred['Price']]})\n",
    "    dfs.append(data)\n",
    "    \n",
    "write_to_csv(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
